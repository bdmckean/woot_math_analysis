{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import json\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "from math import log10, floor\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup db access\n"
     ]
    }
   ],
   "source": [
    "## Connect to local DB\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "print (\"Setup db access\")\n",
    "#\n",
    "# Get collections from mongodb\n",
    "#\n",
    "\n",
    "db = client.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find all qual_id's\n",
    "qual_ids =  db.anon_student_task_responses.distinct('qual_id')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print (len(qual_ids), qual_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get count of qual_id with failures\n",
    "qual_id_counts =  db.anon_student_task_responses.aggregate(\n",
    "  [{           \n",
    "    '$group': {\n",
    "      '_id': {\n",
    "        'qual_id': '$qual_id'\n",
    "      },\n",
    "      'count': {\n",
    "        '$sum': 1\n",
    "      }\n",
    "    }\n",
    "    \n",
    "  }\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " qual_id_counts = list(qual_id_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qual_count_df = pd.DataFrame(qual_id_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print (qual_id_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print (qual_count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qual_count_df = qual_count_df.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qual_count_df.reset_index(drop=True,inplace=True)\n",
    "# print (qual_count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qual_id_fail_counts =  db.anon_student_task_responses.aggregate(\n",
    "  [{           \n",
    "    '$group': {\n",
    "      '_id': {\n",
    "        'qual_id': '$qual_id',\n",
    "        'correct': 'False'             \n",
    "      },\n",
    "      'count': {\n",
    "        '$sum': 1\n",
    "      }\n",
    "    }\n",
    "    \n",
    "  }\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qual_id_fail_counts = list(qual_id_fail_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qual_fail_count_df = pd.DataFrame(qual_id_fail_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qual_fail_count_df.sort_values(by='count', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# qual_fail_count_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Functions for turning dictionary into document\n",
    "\n",
    "def make_string_from_list(key, elem_list):\n",
    "    # Append key to each item in list\n",
    "    ans = ''\n",
    "    for elem in elem_list:\n",
    "        ans += key + '_' + elem \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "def make_string(elem, key=None, top=True):\n",
    "    ans = ''\n",
    "    if not elem:\n",
    "        return ans\n",
    "    if top:\n",
    "        top = False\n",
    "        top_keys = []\n",
    "        for idx in range(len(elem.keys())):\n",
    "            top_keys.append(True)\n",
    "            \n",
    "    for idx, key in enumerate(elem.keys()):\n",
    "        if top_keys[idx]:\n",
    "            top = True\n",
    "            top_keys[idx] = False\n",
    "            ans += ' '\n",
    "        else:\n",
    "            top = False\n",
    "        #print ('ans = ', ans)\n",
    "        #print (type(elem[key]))\n",
    "        if type(elem[key]) is str or\\\n",
    "                type(elem[key]) is int:\n",
    "            #print ('add value', elem[key])\n",
    "            value = str(elem[key])\n",
    "            #ans += key + '_' + value + ' ' + value + ' '\n",
    "            ans += key + '_' + value + ' '\n",
    "        elif type(elem[key]) is list:\n",
    "            #print ('add list', elem[key])\n",
    "            temp_elem = dict()\n",
    "            for item in elem[key]:\n",
    "                temp_elem[key] = item\n",
    "                ans += make_string(temp_elem, top) \n",
    "        elif type(elem[key]) is dict:\n",
    "            #print ('add dict', elem[key])\n",
    "            for item_key in elem[key].keys():\n",
    "                temp_elem = dict()\n",
    "                temp_elem[item_key] = elem[key][item_key]\n",
    "                ans += key + '_' + make_string(temp_elem, top)\n",
    "        elif type(elem[key]) is float:\n",
    "            #print ('add dict', elem[key])\n",
    "            sig = 2\n",
    "            value = elem[key]\n",
    "            value = round(value, sig-int(\n",
    "            floor(log10(abs(value))))-1)\n",
    "            value = str(value)\n",
    "            #ans += key + '_' + value + ' ' + value + ' '\n",
    "            ans += key + '_' + value + ' '\n",
    "        # ans += ' ' + key + ' '\n",
    "        #print ('not handled', elem[key])\n",
    "     \n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_doc_data_set(prob_set):\n",
    "    df3 = pd.DataFrame(list(prob_set))\n",
    "    df3['response_doc'] = df3['response'].map(make_string)\n",
    "    df3['response_doc'] = df3['response_doc'].map(lambda x: x + ' ')\n",
    "    df3['response_doc'] = df3['response_doc'].map(lambda x: x.replace('/','_'))\n",
    "    df3['response_doc'] = df3['response_doc'] + ' ' + df3['txt'] \n",
    "    df3['response_doc'] = df3['response_doc'].map(lambda x: x + ' ')\n",
    "    df3['response_doc'] = df3['response_doc'].map(lambda x: x.replace(\"\\n\", \"\"))\n",
    "    df3['response_doc'] = df3['response_doc'].map(lambda x: x.replace(\"?\", \" \"))\n",
    "    return df3\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_k_means(data_samples, n_features=200, n_topic=30, n_top_words=10, clusters=10):\n",
    "    n_samples = len(data_samples)\n",
    "    print(\"Extracting tf-idf features ...\")\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                       max_features=n_features,\n",
    "                                       stop_words='english')\n",
    "    t0 = time()\n",
    "    tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))\n",
    "    \n",
    "    # Number of clusters\n",
    "    true_k = clusters\n",
    "    km = MiniBatchKMeans(n_clusters=true_k, init='k-means++', n_init=1,\n",
    "                             init_size=1000, batch_size=1000, random_state=62)\n",
    "    print(\"Clustering with %s\" % km)\n",
    "    t0 = time()\n",
    "    km.fit(tfidf)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    return km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_ten_qual_id = qual_count_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "this_qid = top_ten_qual_id.iloc[0]['_id']['qual_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'qual_id': 'xSDXuo9OEH.bonus.OG_XxtbnEa'}</td>\n",
       "      <td>22752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'qual_id': 'YN4n4X5GRF.bonus.Q5XY-9tBFu'}</td>\n",
       "      <td>19100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'qual_id': '9wRCzK1G7F.partb.12d_Yq8M01'}</td>\n",
       "      <td>18911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'qual_id': 'TJxldqZMXd.partb.gqJqOrIhu_'}</td>\n",
       "      <td>18390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'qual_id': 'TJxldqZMXd.partb.9L_iTwGd5z'}</td>\n",
       "      <td>18197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'qual_id': 'TJxldqZMXd.partb.W2tLvQTbkI'}</td>\n",
       "      <td>17800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'qual_id': '9wRCzK1G7F.partb.SHkv5F_Yzi'}</td>\n",
       "      <td>17466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'qual_id': 'TJxldqZMXd.partb.hxS1eqLik1'}</td>\n",
       "      <td>17191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'qual_id': '9wRCzK1G7F.partb.qGGEQyiE_j'}</td>\n",
       "      <td>17007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'qual_id': 'kvig7fcCVc.partb.3y7UMHuR_i'}</td>\n",
       "      <td>16876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          _id  count\n",
       "0  {'qual_id': 'xSDXuo9OEH.bonus.OG_XxtbnEa'}  22752\n",
       "1  {'qual_id': 'YN4n4X5GRF.bonus.Q5XY-9tBFu'}  19100\n",
       "2  {'qual_id': '9wRCzK1G7F.partb.12d_Yq8M01'}  18911\n",
       "3  {'qual_id': 'TJxldqZMXd.partb.gqJqOrIhu_'}  18390\n",
       "4  {'qual_id': 'TJxldqZMXd.partb.9L_iTwGd5z'}  18197\n",
       "5  {'qual_id': 'TJxldqZMXd.partb.W2tLvQTbkI'}  17800\n",
       "6  {'qual_id': '9wRCzK1G7F.partb.SHkv5F_Yzi'}  17466\n",
       "7  {'qual_id': 'TJxldqZMXd.partb.hxS1eqLik1'}  17191\n",
       "8  {'qual_id': '9wRCzK1G7F.partb.qGGEQyiE_j'}  17007\n",
       "9  {'qual_id': 'kvig7fcCVc.partb.3y7UMHuR_i'}  16876"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_qual_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_top_ten = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis 0 for qual_id xSDXuo9OEH.bonus.OG_XxtbnEa with 22752 samples\n"
     ]
    }
   ],
   "source": [
    "for row in range(len(top_ten_qual_id)):\n",
    "    # print (top_ten_qual_id.iloc[row]['_id']['qual_id'], top_ten_qual_id.iloc[row]['count'])\n",
    "\n",
    "    this_qid = top_ten_qual_id.iloc[row]['_id']['qual_id']\n",
    "    count = top_ten_qual_id.iloc[row]['count']\n",
    "    print ('Analysis {0} for qual_id {1} with {2} samples'.format(row, this_qid, count))\n",
    "\n",
    "\n",
    "    prob_set = db.anon_student_task_responses.find({'qual_id':this_qid, 'correct': False})\n",
    "    df3 = make_doc_data_set(prob_set)\n",
    "    print ('Session 0 txt ', df3.iloc[0]['txt'])   \n",
    "    df_top_ten.append(df3.copy())\n",
    "    data_samples = df3['response_doc']\n",
    "    km = make_k_means(data_samples, clusters=10)\n",
    "    print (\"Intertia\", km.inertia_)\n",
    "    df3['cluster'] = km.labels_\n",
    "    print ('qual_id {0} has these clusters'.format(this_qid))\n",
    "    print (df3['cluster'].value_counts())\n",
    "      \n",
    "    \n",
    "    columns = 4\n",
    "    num_images = 8\n",
    "    # Look at top four clusters\n",
    "    # Print \n",
    "    for cluster in (df3['cluster'].value_counts().keys())[:4]:\n",
    "        plt.clf\n",
    "        plt.figure(figsize=(20,10))\n",
    "        print ('Cluster', cluster )\n",
    "\n",
    "        cluster_data = df3[df3['cluster']==cluster]\n",
    "        #print (cluster_data[:10])\n",
    "        images = []\n",
    "        for idx in range(min(num_images, df3['cluster'].value_counts()[cluster])):\n",
    "            #    images.append(Image(cluster_data.iloc[idx]['screenshot_url']))\n",
    "            # create a file-like object from the url\n",
    "            print (cluster_data.iloc[idx]['screenshot_url'])\n",
    "            try:\n",
    "                f = urllib.request.urlopen(cluster_data.iloc[idx]['screenshot_url'])\n",
    "            except:\n",
    "                print(' could not read {0}'.format(cluster_data.iloc[idx]['screenshot_url']))\n",
    "                continue\n",
    "            # read the image file in a numpy array\n",
    "            a = plt.imread(f)\n",
    "            #plt.imshow(a)\n",
    "            #plt.show()\n",
    "            #print(image)\n",
    "            #display(image)\n",
    "            plt.subplot(min(9, df3['cluster'].value_counts()[cluster]) / columns + 1, columns, idx + 1)\n",
    "            plt.imshow(a)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:hwenv]",
   "language": "python",
   "name": "conda-env-hwenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
